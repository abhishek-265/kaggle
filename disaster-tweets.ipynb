{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"../input/nlp-getting-started/train.csv\")\n",
    "test = pd.read_csv(\"../input/nlp-getting-started/test.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Our Deeds are the Reason of this #earthquake M...\n",
       "1               Forest fire near La Ronge Sask. Canada\n",
       "2    All residents asked to 'shelter in place' are ...\n",
       "3    13,000 people receive #wildfires evacuation or...\n",
       "4    Just got sent this photo from Ruby #Alaska as ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train.text\n",
    "y_train = train.target\n",
    "x_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   Just happened a terrible car crash\n",
       "1    Heard about #earthquake is different cities, s...\n",
       "2    there is a forest fire at spot pond, geese are...\n",
       "3             Apocalypse lighting. #Spokane #wildfires\n",
       "4        Typhoon Soudelor kills 28 in China and Taiwan\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = test.text\n",
    "x_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping ={\n",
    "    \"ain't\": \"am not / are not / is not / has not / have not\", \"aren't\": \"are not / am not\", \"can't\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\", \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\", \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he had / he would\", \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he shall / he will\", \"he'll've\": \"he shall have / he will have\", \"he's\": \"he has / he is\",\n",
    "    \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how has / how is / how does\",\n",
    "    \"I'd\": \"I had / I would\", \"I'd've\": \"I would have\", \"I'll\": \"I shall / I will\", \"I'll've\": \"I shall have / I will have\",\n",
    "    \"I'm\": \"I am\", \"I've\": \"I have\", \"isn't\": \"is not\", \"it'd\": \"it had / it would\", \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it shall / it will\", \"it'll've\": \"it shall have / it will have\",\n",
    "    \"it's\": \"it has / it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\", \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\", \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\", \"she'd\": \"she had / she would\", \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she shall / she will\", \"she'll've\": \"she shall have / she will have\",\n",
    "    \"she's\": \"she has / she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\", \"so's\": \"so as / so is\", \"that'd\": \"that would / that had\", \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that has / that is\", \"there'd\": \"there had / there would\", \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there has / there is\", \"they'd\": \"they had / they would\", \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they shall / they will\", \"they'll've\": \"they shall have / they will have\",\n",
    "    \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we had / we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what shall / what will\", \"what'll've\": \"what shall have / what will have\",\n",
    "    \"what're\": \"what are\", \"what's\": \"what has / what is\", \"what've\": \"what have\",\n",
    "    \"when's\": \"when has / when is\", \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\", \"where's\": \"where has / where is\", \"where've\": \"where have\", \"who'll\": \"who shall / who will\",\n",
    "    \"who'll've\": \"who shall have / who will have\", \"who's\": \"who has / who is\", \"who've\": \"who have\",\n",
    "    \"why's\": \"why has / why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\", \"y'all'd\": \"you all would\", \"y'all'd've\": \"you all would have\", \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\", \"you'd\": \"you had / you would\", \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you shall / you will\", \"you'll've\": \"you shall have / you will have\",\n",
    "    \"you're\": \"you are\", \"you've\": \"you have\",\n",
    "    \"he's\" : \"he is\", \"there's\" : \"there is\",\"We're\" : \"We are\",\"That's\" : \"That is\",\"won't\" : \"will not\",\"they're\" : \"they are\",\n",
    "    \"Can't\" : \"Cannot\",\"wasn't\" : \"was not\",\"aren't\" : \"are not\",\"isn't\" : \"is not\",\"What's\" : \"What is\",\"i'd\" : \"I would\",\n",
    "    \"should've\" : \"should have\",\"where's\" : \"where is\",\"we'd\" : \"we would\",\"i'll\" : \"I will\",\"weren't\" : \"were not\",\n",
    "    \"They're\" : \"They are\",\"let's\" : \"let us\",\"it's\" : \"it is\",\"can't\" : \"cannot\",\"don't\" : \"do not\",\"you're\" : \"you are\",\n",
    "    \"i've\" : \"I have\",\"that's\" : \"that is\",\"i'll\" : \"I will\",\"doesn't\" : \"does not\",\"i'd\" : \"I would\",\"didn't\" : \"did not\",\n",
    "    \"ain't\" : \"am not\",\"you'll\" : \"you will\",\"I've\" : \"I have\",\"Don't\" : \"do not\",\"I'll\" : \"I will\",\"I'd\" : \"I would\",\n",
    "    \"Let's\" : \"Let us\",\"you'd\" : \"You would\",\"It's\" : \"It is\",\"Ain't\" : \"am not\",\"Haven't\" : \"Have not\",\"Could've\" : \"Could have\",\n",
    "    \"youve\" : \"you have\",\"haven't\" : \"have not\",\"hasn't\" : \"has not\",\"There's\" : \"There is\",\"He's\" : \"He is\",\"It's\" : \"It is\",\n",
    "    \"You're\" : \"You are\",\"I'M\" : \"I am\",\"shouldn't\" : \"should not\",\"wouldn't\" : \"would not\",\"i'm\" : \"I am\",\"I'm\" : \"I am\",\n",
    "    \"Isn't\" : \"is not\",\"Here's\" : \"Here is\",\"you've\" : \"you have\",\"we're\" : \"we are\",\"what's\" : \"what is\",\"couldn't\" : \"could not\",\n",
    "    \"we've\" : \"we have\",\"who's\" : \"who is\",\"y'all\" : \"you all\",\"would've\" : \"would have\",\"it'll\" : \"it will\",\"we'll\" : \"we will\",\n",
    "    \"We've\" : \"We have\",\"he'll\" : \"he will\",\"Y'all\" : \"You all\",\"Weren't\" : \"Were not\",\"Didn't\" : \"Did not\",\"they'll\" : \"they will\",\n",
    "    \"they'd\" : \"they would\",\"DON'T\" : \"DO NOT\",\"they've\" : \"they have\",\n",
    "    \n",
    "    #correct some acronyms while we are at it\n",
    "    \"tnwx\" : \"Tennessee Weather\", \"azwx\" : \"Arizona Weather\", \"alwx\" : \"Alabama Weather\", \"wordpressdotcom\" : \"wordpress\",\n",
    "    \"gawx\" : \"Georgia Weather\", \"scwx\" : \"South Carolina Weather\", \"cawx\" : \"California Weather\",\n",
    "    \"usNWSgov\" : \"United States National Weather Service\", \"MH370\" : \"Malaysia Airlines Flight 370\",\n",
    "    \"okwx\" : \"Oklahoma City Weather\", \"arwx\" : \"Arkansas Weather\",  \"lmao\" : \"laughing my ass off\",  \n",
    "    \"amirite\" : \"am I right\",\n",
    "    \n",
    "    #and some typos/abbreviations\n",
    "    \"w/e\" : \"whatever\", \"w/\" : \"with\", \"USAgov\" : \"USA government\", \"recentlu\" : \"recently\", \"Ph0tos\" : \"Photos\", \n",
    "    \"exp0sed\" : \"exposed\", \"<3\" : \"love\", \"amageddon\" : \"armageddon\", \"Trfc\" : \"Traffic\", \"WindStorm\" : \"Wind Storm\",\n",
    "    \"16yr\" : \"16 year\", \"TRAUMATISED\" : \"traumatized\",\n",
    "    \n",
    "    #hashtags and usernames\n",
    "    \"IranDeal\" : \"Iran Deal\", \"ArianaGrande\" : \"Ariana Grande\", \"camilacabello97\" : \"camila cabello\", \n",
    "    \"RondaRousey\" : \"Ronda Rousey\", \"MTVHottest\" : \"MTV Hottest\", \"TrapMusic\" : \"Trap Music\",\n",
    "    \"ProphetMuhammad\" : \"Prophet Muhammad\", \"PantherAttack\" : \"Panther Attack\", \"StrategicPatience\" : \"Strategic Patience\",\n",
    "    \"socialnews\" : \"social news\", \"IDPs:\" : \"Internally Displaced People :\", \"ArtistsUnited\" : \"Artists United\",\n",
    "    \"ClaytonBryant\" : \"Clayton Bryant\", \"jimmyfallon\" : \"jimmy fallon\", \"justinbieber\" : \"justin bieber\", \"Time2015\" : \"Time 2015\",\n",
    "    \"djicemoon\" : \"dj icemoon\", \"LivingSafely\" : \"Living Safely\", \"FIFA16\" : \"Fifa 2016\",\n",
    "    \"thisiswhywecanthavenicethings\" : \"this is why we cannot have nice things\", \"bbcnews\" : \"bbc news\",\n",
    "    \"UndergroundRailraod\" : \"Underground Railraod\", \"c4news\" : \"c4 news\", \"MUDSLIDE\" : \"mudslide\", \"NoSurrender\" : \"No Surrender\",\n",
    "    \"NotExplained\" : \"Not Explained\", \"greatbritishbakeoff\" : \"great british bake off\", \"LondonFire\" : \"London Fire\",\n",
    "    \"KOTAWeather\" : \"KOTA Weather\", \"LuchaUnderground\" : \"Lucha Underground\", \"KOIN6News\" : \"KOIN 6 News\",\n",
    "    \"LiveOnK2\" : \"Live On K2\", \"9NewsGoldCoast\" : \"9 News Gold Coast\", \"nikeplus\" : \"nike plus\", \"david_cameron\" : \"David Cameron\",\n",
    "    \"peterjukes\" : \"Peter Jukes\", \"MikeParrActor\" : \"Michael Parr\", \"4PlayThursdays\" : \"Foreplay Thursdays\",\n",
    "    \"TGF2015\" : \"Tontitown Grape Festival\", \"realmandyrain\" : \"Mandy Rain\", \"GraysonDolan\" : \"Grayson Dolan\", \n",
    "    \"ApolloBrown\" : \"Apollo Brown\", \"saddlebrooke\" : \"Saddlebrooke\", \"TontitownGrape\" : \"Tontitown Grape\", \"AbbsWinston\" : \"Abbs Winston\",\n",
    "    \"ShaunKing\" : \"Shaun King\", \"MeekMill\" : \"Meek Mill\", \"TornadoGiveaway\" : \"Tornado Giveaway\", \"GRupdates\" : \"GR updates\",\n",
    "    \"SouthDowns\" : \"South Downs\", \"braininjury\" : \"brain injury\", \"auspol\" : \"Australian politics\", \"PlannedParenthood\" : \"Planned Parenthood\",\n",
    "    \"calgaryweather\" : \"Calgary Weather\", \"weallheartonedirection\" : \"we all heart one direction\", \"edsheeran\" : \"Ed Sheeran\",\n",
    "    \"TrueHeroes\" : \"True Heroes\", \"ComplexMag\" : \"Complex Magazine\", \"TheAdvocateMag\" : \"The Advocate Magazine\",\n",
    "    \"CityofCalgary\" : \"City of Calgary\", \"EbolaOutbreak\" : \"Ebola Outbreak\", \"SummerFate\" : \"Summer Fate\",\n",
    "    \"RAmag\" : \"Royal Academy Magazine\", \"offers2go\" : \"offers to go\", \"ModiMinistry\" : \"Modi Ministry\", \"TAXIWAYS\" : \"taxi ways\",\n",
    "    \"Calum5SOS\" : \"Calum Hood\", \"JamesMelville\" : \"James Melville\", \"JamaicaObserver\" : \"Jamaica Observer\",\n",
    "    \"TweetLikeItsSeptember11th2001\" : \"Tweet like it is september 11th 2001\", \"cbplawyers\" : \"cbp lawyers\",\n",
    "    \"fewmoretweets\" : \"few more tweets\", \"BlackLivesMatter\" : \"Black Lives Matter\", \"NASAHurricane\" : \"NASA Hurricane\",\n",
    "    \"onlinecommunities\" : \"online communities\", \"humanconsumption\" : \"human consumption\", \"Typhoon-Devastated\" : \"Typhoon Devastated\",\n",
    "    \"Meat-Loving\" : \"Meat Loving\", \"facialabuse\" : \"facial abuse\", \"LakeCounty\" : \"Lake County\", \"BeingAuthor\" : \"Being Author\",\n",
    "    \"withheavenly\" : \"with heavenly\", \"thankU\" : \"thank you\", \"iTunesMusic\" : \"iTunes Music\",\n",
    "    \"OffensiveContent\" : \"Offensive Content\", \"WorstSummerJob\" : \"Worst Summer Job\", \"HarryBeCareful\" : \"Harry Be Careful\",\n",
    "    \"NASASolarSystem\" : \"NASA Solar System\", \"animalrescue\" : \"animal rescue\", \"KurtSchlichter\" : \"Kurt Schlichter\",\n",
    "    \"Throwingknifes\" : \"Throwing knives\", \"GodsLove\" : \"God's Love\", \"bookboost\" : \"book boost\", \"ibooklove\" : \"I book love\",\n",
    "    \"NestleIndia\" : \"Nestle India\", \"realDonaldTrump\" : \"Donald Trump\", \"DavidVonderhaar\" : \"David Vonderhaar\", \"CecilTheLion\" : \"Cecil The Lion\",\n",
    "    \"weathernetwork\" : \"weather network\", \"GOPDebate\" : \"GOP Debate\",\n",
    "    \"RickPerry\" : \"Rick Perry\", \"frontpage\" : \"front page\", \"NewsInTweets\" : \"News In Tweets\",\n",
    "    \"ViralSpell\" : \"Viral Spell\", \"til_now\" : \"until now\",\n",
    "    \"volcanoinRussia\" : \"volcano in Russia\", \"ZippedNews\" : \"Zipped News\", \"MicheleBachman\" : \"Michele Bachman\",\n",
    "    \"53inch\" : \"53 inch\", \"KerrickTrial\" : \"Kerrick Trial\", \"abstorm\" : \"Alberta Storm\", \"Beyhive\" : \"Beyonce hive\",\n",
    "    \"RockyFire\" : \"Rocky Fire\",\"Listen/Buy\" : \"Listen / Buy\",\"ArtistsUnited\" : \"Artists United\",\n",
    "    \"ENGvAUS\" : \"England vs Australia\", \"ScottWalker\" : \"Scott Walker\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_re = re.compile('(%s)' % '|'.join(contraction_mapping.keys()))\n",
    "def expand_contractions(s, contraction_mapping=contraction_mapping):\n",
    "    def replace(match):\n",
    "        return contraction_mapping[match.group(0)]\n",
    "    return contractions_re.sub(replace, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(t):\n",
    "    ids = []\n",
    "    index = 0\n",
    "    for i in range(len(t.split())):\n",
    "        if \"http\" in t.split()[i] or \"@\" in t.split()[i]:\n",
    "            index = i\n",
    "            ids.append(index)\n",
    "    tex = []\n",
    "    for i in range(len(t.split())):\n",
    "        if i not in ids:\n",
    "            tex.append(t.split()[i])\n",
    "    return (\" \".join(tex)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    text = clean(text)\n",
    "    newString = expand_contractions(text)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    newString = re.sub(\"\\W\", \" \", newString)\n",
    "    tokens = [w for w in newString.split() if w not in stop_words]\n",
    "    long_words = []\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                                 #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Our Deeds Reason earthquake May ALLAH Forgive us',\n",
       " 'Forest fire near La Ronge Sask Canada',\n",
       " 'All residents asked shelter place notified officers No evacuation shelter place orders expected',\n",
       " 'people receive wildfires evacuation orders California',\n",
       " 'Just got sent photo Ruby Alaska smoke wildfires pours school',\n",
       " 'Rocky Fire Update California Hwy closed directions due Lake County fire CAfire wildfires',\n",
       " 'flood disaster Heavy rain causes flash flooding streets Manitou Colorado Springs areas',\n",
       " 'top hill see fire woods',\n",
       " 'There emergency evacuation happening building across street',\n",
       " 'afraid tornado coming area']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the function\n",
    "train_text = []\n",
    "for t in x_train:\n",
    "    train_text.append(text_cleaner(t))\n",
    "train_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Just happened terrible car crash',\n",
       " 'Heard earthquake different cities stay safe everyone',\n",
       " 'forest fire spot pond geese fleeing across street cannot save',\n",
       " 'Apocalypse lighting Spokane wildfires',\n",
       " 'Typhoon Soudelor kills China Taiwan',\n",
       " 'We shaking It earthquake',\n",
       " 'They probably still show life Arsenal yesterday eh EH',\n",
       " 'Hey How',\n",
       " 'What nice hat',\n",
       " 'Fuck']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#call the function\n",
    "test_text = []\n",
    "for t in x_test:\n",
    "    test_text.append(text_cleaner(t))\n",
    "test_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_text+test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10876, 17094)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "df = vectorizer.fit_transform(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7613, 17094), (3263, 17094))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = df[:7613]\n",
    "x_test = df[7613:]\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr, x_val, y_tr, y_val = train_test_split(x_train,y_train, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression()\n",
    "clf.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[821, 233],\n",
       "       [ 65, 404]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_pred, y_val)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model is 80.4333552199606%\n"
     ]
    }
   ],
   "source": [
    "accuracy_score = clf.score(x_val, y_val)\n",
    "print(\"Accuracy of the model is \" + str(accuracy_score*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       0\n",
       "2         3       1\n",
       "3         9       0\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       0\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       1\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = test.id\n",
    "submission['target'] = clf.predict(x_test)\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved\n"
     ]
    }
   ],
   "source": [
    "submission.to_csv('submission.csv', index = False)\n",
    "print('Submission saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
